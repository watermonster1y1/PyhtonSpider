## 沙袋通知爬虫食用指南

[toc]

### 依赖

#### 1.1 Python

前往python[官网](https://www.python.org/downloads/)下载

安装时务必勾选此项，安装`pip`

![python install](.\res\python install.png)

#### 1.2 Scrapy

安装python后，进入终端或CMD。

运行以下命令

```
pip install scrapy
```

#### 1.3 Urllib

运行

```
pip install urllib
```

#### 1.4 PyMySQL

运行

```
pip install pymysql
```

#### 提示

如果pip下载过慢，可以在指令后加上`-i https://pypi.tuna.tsinghua.edu.cn/simple`以切换到国内源

### 使用指南

#### 2.1 修改数据库参数

编辑`.\tongzhi\settings.py`第63行到第68行

```python
DB_HOST = '数据库地址'
DB_PORT = 端口(MySQL默认3306)
DB_USER = '用户名'
DB_PASSWORD = '密码'
DB_NAME = '数据库名'
DB_CHARSET = '字符集'
```

#### 2.2运行爬虫

进入`.\tongzhi\spiders\`目录，启动终端，运行以下指令：

```
scrapy crawl TongzhiSpider
```

#### 2.3 下载管道

编辑`.\tongzhi\settings.py`第73、74两行

本地下载管道为73行，数据库为74行，注释即关闭

```python
ITEM_PIPELINES = {
    #'tongzhi.pipelines.ZhihuPipeline': 1,
    'tongzhi.pipelines.MysqlPipeline': 1,
}
```

默认开启数据库管道，关闭本地管道

数字表示优先级，数字越小优先级越高
